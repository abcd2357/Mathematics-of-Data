{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework_1 / Sept. 2020  / Kangyan Xu\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wdbc.data', header = None)\n",
    "# number = data.shape[0] # number of patients\n",
    "# print(number)\n",
    "output = data.iloc[:,1] # 0-benign or 1-malignant\n",
    "feature_raw = data.iloc[:,2:32] # Each has 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2 Normalize\n",
    "mean = np.mean(feature_raw) # mean vector\n",
    "feature_substracted = feature_raw-mean\n",
    "\n",
    "feature = normalize(feature_substracted, axis = 1, norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  4.  6.  5.  8.  4.  1.  7.  5.  7.  6.  1.  8. 10.  6.  7.  8.  2.\n",
      "  6.  3.  3.  6.  4.  2.  4.  6.  4.  5.  7.  8.  5.  5.  7.  7.  4.  2.\n",
      "  5.  6.  2.  3.  4.  4.  2.  4.  4.  4.  4.  8.  3.  6.  3.  6.  1.  5.\n",
      "  1.  4.  3.  6.  4.  6.  1.  5.  5.  4.  4.  2.  7.  5.  5.  5.  3.  2.\n",
      "  8.  6.  2.  1.  4.  6.  8.  3.  3.  7.  4.  4.  4.  3.  7.  6.  6.  9.\n",
      "  6.  3.  3.  4.  4.  7.  5.  4.  5.  3.]\n",
      "The average error over the 100 trials is 4.67\n"
     ]
    }
   ],
   "source": [
    "partition = 100 # perform 100 random partitions\n",
    "T = 500 # run gradient descent 500 iterations\n",
    "step_size = 0.01\n",
    "lamda = 0.01\n",
    "error = np.zeros(partition)\n",
    "\n",
    "# weight_without_bias\n",
    "indicator = np.ones([31, 1])\n",
    "indicator[30] = 0\n",
    "\n",
    "for i in range(partition):\n",
    "    \n",
    "    weight = np.ones([30+1, 1]) # this weight contains bias b as last item\n",
    "    \n",
    "    # partition: 500 train data & 69 test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, output, test_size = 69, random_state = i)\n",
    "    # Series to DataFrame\n",
    "    y_train = y_train.to_frame().values\n",
    "    \n",
    "    # Add a column with all 1's / X_train 500,31\n",
    "    X_train = np.column_stack((X_train, np.ones([500, 1])))\n",
    "\n",
    "    # run gradient descent\n",
    "    for j in range(T):\n",
    "        \n",
    "        temp = sigmoid(np.dot(X_train, weight)) - y_train # 1/XW - y / temp 500,1\n",
    "        gradient = np.dot(X_train.T, temp) + lamda * (indicator * weight) # !! Don't put L2-regularization out\n",
    "        weight = weight - step_size * gradient\n",
    "    \n",
    "    # prediction on test data\n",
    "    X_test = np.column_stack((X_test, np.ones([69, 1])))\n",
    "    y_test = y_test.to_frame().values\n",
    "    \n",
    "    prediction = np.round(sigmoid(np.dot(X_test, weight)))\n",
    "    \n",
    "    error[i] = int(69-sum(y_test == prediction))\n",
    "\n",
    "print(error)\n",
    "average_err = np.sum(error)/100\n",
    "print(\"The average error over the 100 trials is %.2f\" %average_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11473. 11266. 11520. 11381. 12234. 11318. 11810. 11257. 11367. 10992.\n",
      " 11619. 10871. 12052. 10784. 11919. 12872. 10792. 11139. 11212. 11616.\n",
      " 11816. 12342. 11694. 11032. 11276. 11922. 12539. 11193. 12152. 12016.\n",
      " 11836. 11873. 12361. 11567. 11355. 11085. 12118. 11387. 11188. 11124.\n",
      " 11425. 11444. 11383. 11226. 11447. 11377. 11065. 11363. 13403. 12728.\n",
      " 11449. 11382. 11205. 10875. 12683. 11037. 11550. 11139. 12220. 11142.\n",
      " 11759. 11216. 11546. 11072. 11380. 11675. 11258. 11758. 11561. 11801.\n",
      " 11811. 10765. 12705. 11937. 11387. 11303. 11347. 11155. 10905. 11087.\n",
      " 11071. 11385. 11154. 10915. 11086. 12417. 11785. 12349. 12167. 11336.\n",
      " 10893. 11202. 11602. 11169. 10884. 11728. 11524. 11576. 10811. 11360.]\n",
      "[[9.99985152e-07]]\n",
      "The average iterations over the 100 trials is 11527\n"
     ]
    }
   ],
   "source": [
    "### Calculate iterations needed for 10e-6 accuracy\n",
    "\n",
    "partition = 100 # perform 100 random partitions\n",
    "step_size = 0.01\n",
    "lamda = 0.01\n",
    "iterations = np.zeros(partition)\n",
    "\n",
    "# weight_without_bias\n",
    "indicator = np.ones([31, 1])\n",
    "indicator[30] = 0\n",
    "\n",
    "for i in range(partition):\n",
    "    \n",
    "    weight = np.ones([30+1, 1]) # this weight contains bias b as last item\n",
    "    \n",
    "    # partition: 500 train data & 69 test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, output, test_size = 69, random_state = i)\n",
    "    # Series to DataFrame\n",
    "    y_train = y_train.to_frame().values\n",
    "    \n",
    "    # Add a column with all 1's / X_train 500,31\n",
    "    X_train = np.column_stack((X_train, np.ones([500, 1])))\n",
    "\n",
    "    # run gradient descent\n",
    "    while True:\n",
    "        \n",
    "        iterations[i] += 1\n",
    "\n",
    "        temp = sigmoid(np.dot(X_train, weight)) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "        gradient = np.dot(X_train.T, temp) + lamda * (indicator * weight)\n",
    "        weight = weight - step_size * gradient\n",
    "        \n",
    "        temp_new = sigmoid(np.dot(X_train, weight)) - y_train\n",
    "        gradient_new = np.dot(X_train.T, temp_new) + lamda * (indicator * weight)\n",
    "        \n",
    "        # accuracy\n",
    "        gradient_norm_sqr = np.square(np.linalg.norm(gradient_new, axis = 0))\n",
    "        weight_without_bias_norm_sqr = np.square(np.linalg.norm(indicator * weight, axis = 0))\n",
    "        Xw = np.dot(X_train, weight)\n",
    "        function_value = - np.dot(y_train.T, Xw) + np.sum(np.logaddexp(Xw, np.e)) + lamda / 2 * weight_without_bias_norm_sqr\n",
    "    \n",
    "        accuracy = gradient_norm_sqr / (1 + np.abs(function_value))\n",
    "        if accuracy <= 1e-6:\n",
    "            break\n",
    "    \n",
    "print(iterations)\n",
    "print(accuracy)\n",
    "average_iter = np.sum(iterations)/100\n",
    "print(\"The average iterations over the 100 trials is %d\" %average_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1401. 1402. 1405. 1409. 1412. 1403. 1397. 1403. 1400. 1402. 1405. 1405.\n",
      " 1404. 1408. 1401. 1405. 1405. 1406. 1402. 1402. 1403. 1406. 1402. 1404.\n",
      " 1403. 1407. 1406. 1401. 1406. 1408. 1405. 1403. 1405. 1408. 1403. 1400.\n",
      " 1405. 1404. 1404. 1402. 1403. 1404. 1402. 1402. 1406. 1407. 1402. 1403.\n",
      " 1403. 1401. 1406. 1405. 1402. 1404. 1405. 1401. 1404. 1404. 1401. 1398.\n",
      " 1402. 1405. 1403. 1400. 1404. 1398. 1403. 1405. 1403. 1399. 1402. 1401.\n",
      " 1405. 1406. 1403. 1404. 1402. 1402. 1406. 1402. 1403. 1405. 1403. 1400.\n",
      " 1402. 1403. 1404. 1406. 1406. 1401. 1407. 1401. 1404. 1400. 1402. 1406.\n",
      " 1400. 1402. 1403. 1404.]\n",
      "[[9.96141206e-07]]\n",
      "Heavy ball: The average iterations over the 100 trials is 1403\n"
     ]
    }
   ],
   "source": [
    "### Calculate iterations needed for 10e-6 accuracy with momentum term - heavy ball method\n",
    "\n",
    "partition = 100 # perform 100 random partitions\n",
    "step_size = 0.01\n",
    "lamda = 0.01\n",
    "eta = 0.96 # 0.85~1\n",
    "iterations = np.zeros(partition)\n",
    "\n",
    "# weight_without_bias\n",
    "indicator = np.ones([31, 1])\n",
    "indicator[30] = 0\n",
    "\n",
    "for i in range(partition):\n",
    "    \n",
    "    weight = np.ones([30+1, 1]) # this weight contains bias b as last item\n",
    "    weight_last = np.zeros([31, 1])\n",
    "    weight_new = np.zeros([31, 1])\n",
    "    \n",
    "    # partition: 500 train data & 69 test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, output, test_size = 69, random_state = i)\n",
    "    # Series to DataFrame\n",
    "    y_train = y_train.to_frame().values\n",
    "    \n",
    "    # Add a column with all 1's / X_train 500,31\n",
    "    X_train = np.column_stack((X_train, np.ones([500, 1])))\n",
    "\n",
    "    # run gradient descent (heavy ball)\n",
    "    while True:\n",
    "        \n",
    "        iterations[i] += 1\n",
    "\n",
    "        temp = sigmoid(np.dot(X_train, weight)) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "        gradient = np.dot(X_train.T, temp) + lamda * (indicator * weight)\n",
    "        weight_new = weight - step_size * gradient + eta * (weight - weight_last)\n",
    "        weight_last = weight\n",
    "        weight = weight_new\n",
    "        \n",
    "        temp_new = sigmoid(np.dot(X_train, weight)) - y_train\n",
    "        gradient_new = np.dot(X_train.T, temp_new) + lamda * (indicator * weight)\n",
    "        \n",
    "        # accuracy\n",
    "        gradient_norm_sqr = np.square(np.linalg.norm(gradient_new, axis = 0))\n",
    "        weight_without_bias_norm_sqr = np.square(np.linalg.norm(indicator * weight, axis = 0))\n",
    "        Xw = np.dot(X_train, weight)\n",
    "        function_value = - np.dot(y_train.T, Xw) + np.sum(np.logaddexp(Xw, np.e)) + lamda / 2 * weight_without_bias_norm_sqr\n",
    "    \n",
    "        accuracy = gradient_norm_sqr / (1 + np.abs(function_value))\n",
    "        if accuracy <= 1e-6:\n",
    "            break\n",
    "    \n",
    "print(iterations)\n",
    "print(accuracy)\n",
    "average_iter = np.sum(iterations)/100\n",
    "print(\"Heavy ball: The average iterations over the 100 trials is %d\" %average_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1404. 1404. 1408. 1411. 1414. 1405. 1400. 1406. 1402. 1405. 1407. 1407.\n",
      " 1406. 1411. 1404. 1408. 1408. 1408. 1405. 1404. 1405. 1408. 1405. 1407.\n",
      " 1406. 1410. 1408. 1404. 1408. 1410. 1408. 1406. 1408. 1410. 1405. 1403.\n",
      " 1407. 1407. 1406. 1405. 1406. 1407. 1405. 1405. 1409. 1410. 1404. 1406.\n",
      " 1405. 1403. 1408. 1408. 1405. 1407. 1408. 1403. 1407. 1406. 1404. 1401.\n",
      " 1405. 1407. 1406. 1403. 1406. 1401. 1406. 1408. 1405. 1402. 1404. 1404.\n",
      " 1407. 1408. 1406. 1407. 1405. 1405. 1408. 1405. 1406. 1408. 1406. 1403.\n",
      " 1405. 1406. 1407. 1408. 1409. 1404. 1409. 1404. 1407. 1403. 1405. 1408.\n",
      " 1403. 1404. 1406. 1406.]\n",
      "[[9.99822097e-07]]\n",
      "Nesterov: The average iterations over the 100 trials is 1406\n"
     ]
    }
   ],
   "source": [
    "### Calculate iterations needed for 10e-6 accuracy with momentum term - Nesterov\n",
    "\n",
    "partition = 100 # perform 100 random partitions\n",
    "step_size = 0.01\n",
    "lamda = 0.01\n",
    "eta = 0.96 # 0.85~1\n",
    "iterations = np.zeros(partition)\n",
    "\n",
    "# weight_without_bias\n",
    "indicator = np.ones([31, 1])\n",
    "indicator[30] = 0\n",
    "\n",
    "for i in range(partition):\n",
    "    \n",
    "    weight = np.ones([30+1, 1]) # this weight contains bias b as last item\n",
    "    weight_last = np.zeros([31, 1])\n",
    "    weight_new = np.zeros([31, 1])\n",
    "    \n",
    "    # partition: 500 train data & 69 test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, output, test_size = 69, random_state = i)\n",
    "    # Series to DataFrame\n",
    "    y_train = y_train.to_frame().values\n",
    "    \n",
    "    # Add a column with all 1's / X_train 500,31\n",
    "    X_train = np.column_stack((X_train, np.ones([500, 1])))\n",
    "\n",
    "    # run gradient descent (heavy ball)\n",
    "    while True:\n",
    "        \n",
    "        iterations[i] += 1\n",
    "\n",
    "        temp_Nesterov = sigmoid(np.dot(X_train, weight + eta * (weight - weight_last))) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "        gradient_Nesterov = np.dot(X_train.T, temp_Nesterov) + lamda * (indicator * (weight + eta * (weight - weight_last)))\n",
    "        weight_new = weight - step_size * gradient_Nesterov + eta * (weight - weight_last)\n",
    "        weight_last = weight\n",
    "        weight = weight_new\n",
    "                                                                        \n",
    "        temp_new = sigmoid(np.dot(X_train, weight)) - y_train\n",
    "        gradient_new = np.dot(X_train.T, temp_new) + lamda * (indicator * weight)\n",
    "                                                                        \n",
    "        # accuracy\n",
    "        gradient_norm_sqr = np.square(np.linalg.norm(gradient_new, axis = 0))\n",
    "        weight_without_bias_norm_sqr = np.square(np.linalg.norm(indicator * weight, axis = 0))\n",
    "        Xw = np.dot(X_train, weight)\n",
    "        function_value = - np.dot(y_train.T, Xw) + np.sum(np.logaddexp(Xw, np.e)) + lamda / 2 * weight_without_bias_norm_sqr\n",
    "    \n",
    "        accuracy = gradient_norm_sqr / (1 + np.abs(function_value))\n",
    "        if accuracy <= 1e-6:\n",
    "            break\n",
    "    \n",
    "print(iterations)\n",
    "print(accuracy)\n",
    "average_iter = np.sum(iterations)/100\n",
    "print(\"Nesterov: The average iterations over the 100 trials is %d\" %average_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ratio Comparison (one trial)\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = 500\n",
    "step_size = 0.01\n",
    "lamda = 0.01\n",
    "eta = 0.96 # 0.85~1\n",
    "\n",
    "# weight_without_bias\n",
    "indicator = np.ones([31, 1])\n",
    "indicator[30] = 0\n",
    "\n",
    "accuracy_gradient_descent = np.zeros(500)\n",
    "accuracy_heavy_ball = np.zeros(500)\n",
    "accuracy_Nesterov = np.zeros(500)\n",
    "\n",
    "weight = np.ones([30+1, 1]) # this weight contains bias b as last item\n",
    "weight_H = np.ones([30+1, 1])\n",
    "weight_last_H = np.zeros([31, 1])\n",
    "weight_new_H = np.zeros([31, 1])\n",
    "weight_N = np.ones([30+1, 1])\n",
    "weight_last_N = np.zeros([31, 1])\n",
    "weight_new_N = np.zeros([31, 1])\n",
    "    \n",
    "# partition: 500 train data & 69 test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, output, test_size = 69, random_state = 37)\n",
    "# Series to DataFrame\n",
    "y_train = y_train.to_frame().values\n",
    "    \n",
    "# Add a column with all 1's / X_train 500,31\n",
    "X_train = np.column_stack((X_train, np.ones([500, 1])))\n",
    "\n",
    "# run gradient descent\n",
    "for i in range(T):\n",
    "\n",
    "    # ---------------------------------------- Gradient Descent ---------------------------------------- #\n",
    "    \n",
    "    temp = sigmoid(np.dot(X_train, weight)) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "    gradient = np.dot(X_train.T, temp) + lamda * (indicator * weight)\n",
    "    weight = weight - step_size * gradient\n",
    "        \n",
    "    temp_new = sigmoid(np.dot(X_train, weight)) - y_train\n",
    "    gradient_new = np.dot(X_train.T, temp_new) + lamda * (indicator * weight)\n",
    "        \n",
    "    # accuracy\n",
    "    gradient_norm_sqr = np.square(np.linalg.norm(gradient_new, axis = 0))\n",
    "    weight_without_bias_norm_sqr = np.square(np.linalg.norm(indicator * weight, axis = 0))\n",
    "    Xw = np.dot(X_train, weight)\n",
    "    function_value = - np.dot(y_train.T, Xw) + np.sum(np.logaddexp(Xw, np.e)) + lamda / 2 * weight_without_bias_norm_sqr\n",
    "    \n",
    "    accuracy_gradient_descent[i] = gradient_norm_sqr / (1 + np.abs(function_value))\n",
    "\n",
    "    # ------------------------------------------- Heavy ball ------------------------------------------ #\n",
    "    \n",
    "    temp_H = sigmoid(np.dot(X_train, weight_H)) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "    gradient_H = np.dot(X_train.T, temp_H) + lamda * (indicator * weight_H)\n",
    "    weight_new_H = weight_H - step_size * gradient_H + eta * (weight_H - weight_last_H)\n",
    "    weight_last_H = weight_H\n",
    "    weight_H = weight_new_H\n",
    "        \n",
    "    temp_new_H = sigmoid(np.dot(X_train, weight_H)) - y_train\n",
    "    gradient_new_H = np.dot(X_train.T, temp_new_H) + lamda * (indicator * weight_H)\n",
    "        \n",
    "    # accuracy\n",
    "    gradient_norm_sqr_H = np.square(np.linalg.norm(gradient_new_H, axis = 0))\n",
    "    weight_without_bias_norm_sqr_H = np.square(np.linalg.norm(indicator * weight_H, axis = 0))\n",
    "    Xw_H = np.dot(X_train, weight_H)\n",
    "    function_value_H = - np.dot(y_train.T, Xw_H) + np.sum(np.logaddexp(Xw_H, np.e)) + lamda / 2 * weight_without_bias_norm_sqr_H\n",
    "    \n",
    "    accuracy_heavy_ball[i] = gradient_norm_sqr_H / (1 + np.abs(function_value_H))\n",
    "    \n",
    "    # ------------------------------------------- Nesterov ------------------------------------------ #\n",
    "    \n",
    "    temp_Nesterov = sigmoid(np.dot(X_train, weight_N + eta * (weight_N - weight_last_N))) - y_train # sigmoid(XW) - y / temp 500,1\n",
    "    gradient_Nesterov = np.dot(X_train.T, temp_Nesterov) + lamda * (indicator * (weight_N + eta * (weight_N - weight_last_N)))\n",
    "    weight_new_N = weight_N - step_size * gradient_Nesterov + eta * (weight_N - weight_last_N)\n",
    "    weight_last_N = weight_N\n",
    "    weight_N = weight_new_N\n",
    "                                                                        \n",
    "    temp_new_N = sigmoid(np.dot(X_train, weight_N)) - y_train\n",
    "    gradient_new_N = np.dot(X_train.T, temp_new_N) + lamda * (indicator * weight_N)\n",
    "                                                                        \n",
    "    # accuracy\n",
    "    gradient_norm_sqr_N = np.square(np.linalg.norm(gradient_new_N, axis = 0))\n",
    "    weight_without_bias_norm_sqr_N = np.square(np.linalg.norm(indicator * weight_N, axis = 0))\n",
    "    Xw_N = np.dot(X_train, weight_N)\n",
    "    function_value_N = - np.dot(y_train.T, Xw_N) + np.sum(np.logaddexp(Xw_N, np.e)) + lamda / 2 * weight_without_bias_norm_sqr_N\n",
    "    \n",
    "    accuracy_Nesterov[i] = gradient_norm_sqr_N / (1 + np.abs(function_value_N)) \n",
    "\n",
    "# fig\n",
    "axis_x = np.linspace(1, 500, 500)\n",
    "plt.figure(figsize = (16, 10))\n",
    "plt.scatter(axis_x, accuracy_gradient_descent, s = 4, marker = '.',)\n",
    "plt.scatter(axis_x, accuracy_heavy_ball, s = 1, color = 'g', marker = 's',)\n",
    "plt.scatter(axis_x, accuracy_Nesterov, s = 2, color = 'r', marker = 'x',)\n",
    "plt.ylim(0, 0.1)\n",
    "\n",
    "plt.legend(['Gradient Descent', 'Heavy Ball', 'Nesterov'])\n",
    "plt.title('Ratio - Iteration Number')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Ratio')\n",
    "plt.grid(True)\n",
    "plt.savefig('Ratio - Iteration Number.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
